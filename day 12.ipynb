{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "corpus = [\n",
    "          'Text of first document.',\n",
    "          'Text of the second document made longer.',\n",
    "          'Number three.',\n",
    "          'This is number four.',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = vec.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['document',\n",
       " 'first',\n",
       " 'four',\n",
       " 'is',\n",
       " 'longer',\n",
       " 'made',\n",
       " 'number',\n",
       " 'of',\n",
       " 'second',\n",
       " 'text',\n",
       " 'the',\n",
       " 'this',\n",
       " 'three']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()\n",
    "vec.transform(['A new document']).toarray() #for each word w in vocabulary, see it w exists in the new document 'A new document'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf-idf\n",
    "tf(term, document) -> the frequency of the word in a document/ total number of words in document\n",
    "\n",
    "idf(term) = log2( inverse( total number of documents/ number of dcuments in which the word occurs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidfTrans = TfidfTransformer(smooth_idf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 13)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n",
    "# type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = tfidfTrans.fit_transform(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44782471, 0.63115694, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.44782471, 0.        , 0.44782471,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.30226172, 0.        , 0.        , 0.        , 0.4260028 ,\n",
       "        0.4260028 , 0.        , 0.30226172, 0.4260028 , 0.30226172,\n",
       "        0.4260028 , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.57866699, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.81556393],\n",
       "       [0.        , 0.        , 0.53426056, 0.53426056, 0.        ,\n",
       "        0.        , 0.37907384, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.53426056, 0.        ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Word Embeddings\n",
    "\n",
    "### Parameter learning methods:\n",
    "\n",
    "#### 1. One word context:\n",
    "It takes one word as input and outputs a word. \n",
    "\n",
    "Dimensions: Input is a V x 1 vector; hidden weights: V x N; hidden->output weights: N x V => output dimensions: V x 1\n",
    "\n",
    "Corresponding to the input word, it outputs the probability of each word in the vocabulary to be the context word\n",
    "\n",
    "#### 2. Multi Word Context:\n",
    "It takes multiple context words and outputs a word closest to meaning.\n",
    "\n",
    "Dimensions: Input: C [V X 1] vectors corresponding to C context words; input->hidden layer weights: V x N and the rest is the same as in One Word Context\n",
    "\n",
    "The second point of difference is in the expression for calculating hidden layer.\n",
    "\n",
    "In One word context: h = transpose(W). X\n",
    "\n",
    "In Multi Word CBOW: h = ( transpose(W) * (X1 + X2 + .... XC) ) / C\n",
    "\n",
    "#### 3. Skip Gram:\n",
    "It is the reverse of Multi Word Context, i.e. given a target word it outsputs C contextual words.\n",
    "\n",
    "Dimensions: Input: V X 1; input->hidden weights: V X N; hidden->output weights: C [V X 1] vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Skip grams on pre-trained model:\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splitSen = [sentence.split() for sentence in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Text', 'of', 'first', 'document.'],\n",
       " ['Text', 'of', 'the', 'second', 'document', 'made', 'longer.'],\n",
       " ['Number', 'three.'],\n",
       " ['This', 'is', 'number', 'four.']]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitSen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec(splitSen, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
