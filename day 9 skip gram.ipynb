{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip Gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model:\n",
    "    We train a simple one hidden layered neural network on the training dataset. \n",
    "### Goal:\n",
    "    To find the weights of the hidden layer. We call these weights as 'word vectors'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: \n",
    "\n",
    "The task here is given an input word, find the nearest/next word or to find the probabilities of each word in vocabulary to be its nearest word.\n",
    "Nearest word is defined using an attribute 'window_size'. Let window_size = 2 => nearest words are two words predessor to the given word and two words immediate successor of the given word i.e. 4 words. \n",
    "\n",
    "Example 1: Consider sentence: \"this lazy dog is not moving from here\"\n",
    "for the input word dog, the nearest words (for window_size = 2) are this, lazy, is and not.\n",
    "\n",
    "Skip Gram's model/logic is no rocket science but a simple play of statistics.\n",
    "\n",
    "We consider all the words in training examples and feed the word with its nearest words to the model in pairs and then calculate the probability of each word in the vocabulary to be the nearest word to a given unseen word.\n",
    "\n",
    "For example: consider example 1. For window_size = 2\n",
    "\n",
    "1. input word: 'this'\n",
    "pairs fed to the model: 'this lazy', 'this dog'\n",
    "\n",
    "2. input word: 'lazy'\n",
    "pairs fed to the model: 'this lazy', 'lazy dog', 'lazy is'\n",
    "\n",
    "3. input word: 'dog'\n",
    "pairs fed to the model: 'dog this', 'dog lazy', 'dog is', 'dog not'\n",
    " \n",
    "and so on.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way if we input a word like 'lazy', we have a higher probability of getting 'dog' or 'this' than 'here' or 'from'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
